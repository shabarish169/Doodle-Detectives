{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def vector_to_numpy(drawing, side=256):\n",
    "    image = vector_to_image(drawing, side)\n",
    "    image_array = np.array(image)\n",
    "    return image_array\n",
    "\n",
    "def vector_to_image(drawing, side=256):\n",
    "    drawing = json.loads(drawing)\n",
    "    min_x, min_y, max_x, max_y = calculate_bounding_box(drawing)\n",
    "\n",
    "    # Calculate the offset to center the drawing within the canvas\n",
    "    offset_x = (side - (max_x - min_x + 1)) // 2\n",
    "    offset_y = (side - (max_y - min_y + 1)) // 2\n",
    "\n",
    "    image = Image.new('L', (side, side), color='white')  # Create a white canvas\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for x, y in drawing:\n",
    "        xy = [(x0 - min_x + offset_x, y0 - min_y + offset_y) for x0, y0 in zip(x, y)]\n",
    "        draw.line(xy, fill='black', width=1)\n",
    "\n",
    "    return image\n",
    "\n",
    "def calculate_bounding_box(drawing):\n",
    "    all_x = [x for x, _ in drawing]\n",
    "    all_y = [y for _, y in drawing]\n",
    "\n",
    "    min_x = min(min(x) for x in all_x)\n",
    "    min_y = min(min(y) for y in all_y)\n",
    "    max_x = max(max(x) for x in all_x)\n",
    "    max_y = max(max(y) for y in all_y)\n",
    "\n",
    "    return min_x, min_y, max_x, max_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('doodle-detectives-aiclubiitm/train.csv')#, dtype={'drawing': np.array})\n",
    "class_list = df['word'].unique()\n",
    "classes = {word: index for index, word in enumerate(class_list)}\n",
    "def prediction_to_words(prediction):\n",
    "    return ' '.join((class_list[p] for p in prediction))\n",
    "# df['drawing'] = df['drawing'].map(vector_to_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            # 1 input image. If we had an RGB image, it would be Conv2d(3, 32, 3, padding=1)\n",
    "            # 32 output images, i.e, 32 kernels and 32 output images are produced\n",
    "            nn.ReLU(),\n",
    "            # The activation function\n",
    "            nn.MaxPool2d(4),\n",
    "            # Pooling with 2 x 2 blocks\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            # Now we have those 32 images and we make 64 from them\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4)\n",
    "            # Pooling again\n",
    "        )\n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear((256*256*64)//256, 600),\n",
    "            # The image shape was initially 28 x 28, by pooling we've made it 7 x 7, so we divide by 16\n",
    "            # We multiply by 64 because the model has learnt 64 features.\n",
    "            nn.Linear(600, 128),\n",
    "            nn.Linear(128, 101)\n",
    "            # We have 10 output neurons (1 for each class)\n",
    "        )\n",
    "    def forward(self, inputs):\n",
    "        # inputs = inputs.reshape([inputs.shape[1], inputs.shape[0], 256, 256])\n",
    "        # print(type(inputs))\n",
    "        x = self.convolutions(inputs)\n",
    "        # Functions in convolution layers are run\n",
    "        x = self.fully_connected(x)\n",
    "        # Functions in fully connected layer are run\n",
    "        return x\n",
    "    def predict(self, test_loader, out='SUBMISSION.csv', out_small='sub', i_0=0): # out = None may not be implemented\n",
    "        \"\"\"\n",
    "        Returns the predictions in a csv chosen by out, i_0 is in case you crash and have already done some stuff\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        if not out: total_predictions=[]\n",
    "        for i, (data, ids) in enumerate(iter(test_loader)):\n",
    "            if i_0 > i: continue\n",
    "            predictions = torch.topk(self.forward(data), 3, dim=1)[1]\n",
    "            if out:\n",
    "                df = pd.DataFrame((ids, predictions), columns = ['key_id', 'word'])\n",
    "                df['predictions'] = df['predictions'].map(prediction_to_words)\n",
    "                df.to_csv(f'{out_small}_{i}', index=False)\n",
    "            else: total_predictions.append(predictions)\n",
    "        if not out: return total_predictions\n",
    "        else:\n",
    "            total_predictions = []\n",
    "            for j in range(i+1):\n",
    "                total_predictions.append(pd.read_csv(f'{out_small}_{j}'))\n",
    "            total_predictions = pd.concat(total_predictions)\n",
    "            total_predictions.to_csv(out, index=False)\n",
    "\n",
    "# le = preprocessing.LabelEncoder()\n",
    "class MyDataset():\n",
    "    def __init__(self, data, targets=None, ids=None, train=True):\n",
    "        self.data = data\n",
    "        if train: \n",
    "            self.targets = targets.map(lambda target: classes[target])\n",
    "        if ids: self.ids = ids\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, i):\n",
    "        img = vector_to_numpy(self.data.loc[i])\n",
    "        if train: return (torch.tensor(img, dtype=torch.float32).reshape((1, *img.shape))), torch.tensor(self.targets[i], dtype=torch.int64)\n",
    "        if ids: return (torch.tensor(img, dtype=torch.float32).reshape((1, *img.shape))), torch.tensor(self.ids[i], dtype=torch.int64)\n",
    "        return (torch.tensor(img, dtype=torch.float32).reshape(1, *img.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining one epoch of training\n",
    "def train(model, train_loader, optimizer, loss, ps=50):\n",
    "    # We train the appropriate model with the input data and the appropriate optimizer\n",
    "    # ps is how often we print the accuracy\n",
    "    train_iter = iter(train_loader)\n",
    "    model.train()\n",
    "    # Puts model in train mode\n",
    "    for i, (data, targets) in enumerate(train_iter):\n",
    "        # i is iteration, data = 1 mini batch of images, targets = 1 mini batch target values\n",
    "        # This repeats for all mini batches \n",
    "        # print(targets)\n",
    "        outputs = model.forward(data) # Forward pass\n",
    "        loss_val = loss(outputs, targets) # Loss computation\n",
    "        # print(targets)\n",
    "        optimizer.zero_grad()  # Ensures gradients stored in optimizer are reset before each backward pass\n",
    "        loss_val.backward() # Backward pass\n",
    "        optimizer.step() # Backward pass\n",
    "\n",
    "        if ps and i % ps == 0:\n",
    "            model.eval()\n",
    "            # Puts model in evaluation mode, so we \n",
    "            with torch.no_grad():\n",
    "                print(f\"Loss is {loss_val}\")\n",
    "                predicted = outputs.max(1)[1]\n",
    "                correct = (predicted == targets).sum().item()\n",
    "                accuracy = correct/len(targets)\n",
    "                print(f\"Train accuracy is {accuracy*100:.3f}%\")\n",
    "def accuracy(model, test):\n",
    "    # Evaluate a model given a test loader\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        count = 0\n",
    "        correct = 0\n",
    "        for data, targets in iter(test):\n",
    "            outputs = model.forward(data)\n",
    "            predicted = outputs.max(1)[1] # Maximum output is predicted class\n",
    "            count += len(targets) # Total length of datasetS\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            # This gives a tensor of True and False values and adds no. of True values to correct each iteration\n",
    "        print((predicted == targets).sum().item())\n",
    "        accuracy = correct/count\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cnn = BasicCNN()\n",
    "cnn_optimizer = torch.optim.Adam(basic_cnn.parameters(), lr=2e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, val_index in StratifiedKFold(n_splits=5).split(df['drawing'], df['word']):\n",
    "    df_train = df.loc[train_index].reset_index().drop('index', axis=1)\n",
    "    df_val = df.loc[val_index].reset_index().drop('index', axis=1)\n",
    "    break\n",
    "train_dataset = MyDataset(df_train['drawing'], df_train['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          ...,\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.]]],\n",
      "\n",
      "\n",
      "        [[[255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          ...,\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.]]],\n",
      "\n",
      "\n",
      "        [[[255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          ...,\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          ...,\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.]]],\n",
      "\n",
      "\n",
      "        [[[255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          ...,\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.]]],\n",
      "\n",
      "\n",
      "        [[[255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          ...,\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.]]]]), tensor([ 30,   7,  67,  18,   2,  82,  86,  18,  99,  71,  23,  50,  63,  52,\n",
      "          5,  18,  98,  74,  19,  27,  91,  13,  49,  24,  91,  41,  63,  97,\n",
      "         33,  87,   2,  27,  26,  25,  54,  78,   9,  99,  93,  64,  29,  15,\n",
      "         85,  73,  90,  31,  82,   8,  51,  24,  34,  19,   8,  93,  18,  75,\n",
      "         55,  57,  10,  97,  40,  91,  89,  79,  69,  93,  12,  53,  75,  54,\n",
      "         90,  84,  54,  79,  93,  44,  90,  58,  18,  56,  49,  70,  43,  77,\n",
      "         94,  66,  36,  27,  94,  56,  30,  67,  15,  73,  74,  25,  53,  68,\n",
      "         58,   0,  28,  30,   2,   6,   7,  63, 100,  35,  45,  58,  30,  94,\n",
      "         77,  79,  55,  58,  11,   5,  24,  78,  65,  85,  79,  73,  49,  19,\n",
      "         61,  41])]\n"
     ]
    }
   ],
   "source": [
    "# print(next(iter(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drawing</th>\n",
       "      <th>key_id</th>\n",
       "      <th>word</th>\n",
       "      <th>recognized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[42, 15, 4, 1, 0, 6, 14, 24, 70, 72, 58, 51,...</td>\n",
       "      <td>6077534540136448</td>\n",
       "      <td>headphones</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[92, 96, 111, 147, 183, 211, 225, 238, 238, ...</td>\n",
       "      <td>6466812659105792</td>\n",
       "      <td>headphones</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[11, 8, 15, 45, 69, 81, 99, 107, 87, 52, 43,...</td>\n",
       "      <td>5836209777541120</td>\n",
       "      <td>headphones</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[39, 42, 56, 81, 93, 100, 115, 150, 166, 167...</td>\n",
       "      <td>6335595888508928</td>\n",
       "      <td>headphones</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[48, 62, 83, 129, 160, 184, 208, 216, 228], ...</td>\n",
       "      <td>5763670711730176</td>\n",
       "      <td>headphones</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346082</th>\n",
       "      <td>[[[78, 73, 73, 77, 86, 94, 108, 122, 130, 129,...</td>\n",
       "      <td>4965983666044928</td>\n",
       "      <td>mermaid</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346083</th>\n",
       "      <td>[[[223, 168, 119, 106, 55, 33, 20, 0, 13, 28, ...</td>\n",
       "      <td>5232698266222592</td>\n",
       "      <td>leg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346084</th>\n",
       "      <td>[[[74, 65, 60, 57, 64, 74, 78, 81, 91, 128, 14...</td>\n",
       "      <td>4509987894198272</td>\n",
       "      <td>teddy-bear</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346085</th>\n",
       "      <td>[[[135, 106, 91, 69, 60, 31, 9, 1, 1, 14, 49, ...</td>\n",
       "      <td>4673679432613888</td>\n",
       "      <td>mermaid</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346086</th>\n",
       "      <td>[[[226, 191, 128, 66, 55, 44, 4, 0, 2, 49, 56,...</td>\n",
       "      <td>6144803123232768</td>\n",
       "      <td>whale</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>346087 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  drawing            key_id  \\\n",
       "0       [[[42, 15, 4, 1, 0, 6, 14, 24, 70, 72, 58, 51,...  6077534540136448   \n",
       "1       [[[92, 96, 111, 147, 183, 211, 225, 238, 238, ...  6466812659105792   \n",
       "2       [[[11, 8, 15, 45, 69, 81, 99, 107, 87, 52, 43,...  5836209777541120   \n",
       "3       [[[39, 42, 56, 81, 93, 100, 115, 150, 166, 167...  6335595888508928   \n",
       "4       [[[48, 62, 83, 129, 160, 184, 208, 216, 228], ...  5763670711730176   \n",
       "...                                                   ...               ...   \n",
       "346082  [[[78, 73, 73, 77, 86, 94, 108, 122, 130, 129,...  4965983666044928   \n",
       "346083  [[[223, 168, 119, 106, 55, 33, 20, 0, 13, 28, ...  5232698266222592   \n",
       "346084  [[[74, 65, 60, 57, 64, 74, 78, 81, 91, 128, 14...  4509987894198272   \n",
       "346085  [[[135, 106, 91, 69, 60, 31, 9, 1, 1, 14, 49, ...  4673679432613888   \n",
       "346086  [[[226, 191, 128, 66, 55, 44, 4, 0, 2, 49, 56,...  6144803123232768   \n",
       "\n",
       "              word  recognized  \n",
       "0       headphones        True  \n",
       "1       headphones        True  \n",
       "2       headphones        True  \n",
       "3       headphones       False  \n",
       "4       headphones       False  \n",
       "...            ...         ...  \n",
       "346082     mermaid       False  \n",
       "346083         leg       False  \n",
       "346084  teddy-bear       False  \n",
       "346085     mermaid        True  \n",
       "346086       whale        True  \n",
       "\n",
       "[346087 rows x 4 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_loader.targets.loc[0]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 10,  72,  83,  66,  79,  29,  21,  44,  37,  46,  41,   4,  76,  73,\n",
      "         11,  11,  36,  66,  41,  28,  44,  85,  10,  51,  58,  67,  94,  20,\n",
      "         59,  68,  79,  19,  29,  52,  30,  32,  48,  40,  52,  43,  13,   6,\n",
      "         22,  13,  87,  69,  49,  52,  47,  90,  43,  74,  48,  59,  60,  91,\n",
      "         63,  85,  59,  69,  91,  29,  27,  10,  78,  20,  59,  13, 100,  56,\n",
      "         74,  27,  91,  99,  87,  61,   1,  55,   1,  32,   4,  63,  77,  89,\n",
      "         60,  34,  18,  41,  84,  45,   5,  49,   4,   8,  22,  54,  12,  25,\n",
      "         96,   4,  38,   3,  57,  19,  38,  43,  21,   2,  25,  37,  32,  70,\n",
      "         93,  28,   3,  80,  23,  69,  43,  12,  79,  75,  12,  56,  50,  74,\n",
      "         43,  39])\n",
      "Loss is 19.361553192138672\n",
      "Train accuracy is 0.000%\n",
      "tensor([90,  7, 92, 12, 24, 95, 37, 59, 31, 85,  3, 13, 26, 60, 64, 19, 89, 85,\n",
      "        33, 73, 63, 87, 44, 20, 98, 70, 30, 83, 24,  5, 20, 70, 99, 85, 51, 99,\n",
      "        69, 20, 82, 19, 83, 24, 75, 88, 65, 14, 85, 56, 34, 27,  1, 36, 30, 64,\n",
      "        60, 95, 10, 57, 74, 41, 17, 14, 24, 36, 66, 74, 42, 56, 51, 56, 95, 66,\n",
      "        56, 39, 32, 30, 96,  3, 42, 23, 22, 90, 40, 24, 84,  5, 67, 12, 85, 53,\n",
      "         2, 76, 52, 98, 71, 56, 27, 29, 61, 46,  4, 54, 42, 57, 94, 90, 79, 91,\n",
      "        98, 18, 82, 29, 53, 71, 73, 82, 80, 41, 57, 34, 51, 44, 48, 66,  8, 92,\n",
      "        26, 15])\n",
      "tensor([ 12,  99,  78,  57,  86,  17,  50,  61,  78,  29,   6,  68,  65,   2,\n",
      "          7,  98,  70,  69,  21,  23,  62,   3,  69,  42,  76, 100,  87,   3,\n",
      "         16,  87,  64,  99,  98,  23,  80,  42,  65,  71,  72,  74,  24,  96,\n",
      "         59,  35,  60,  90,  70,  23,  35,   9,  22,  36,  76,   3,  43,  25,\n",
      "         36,  63, 100,  32,  25,  65,  75,  44,  59,  14,  96,  62,  65,  47,\n",
      "         75,  41,  49,  59,  49,  62,  13,  65,  65,  68,  85,  25,  53,  95,\n",
      "         92,  30,  65,  53,  30,  97,  83,  12,  30,  98,  97,  34,  82,  71,\n",
      "         39,  18,  79,  24,  30,  64,  79,  54,  13,  29,  75,  55,  17,  34,\n",
      "         14,  31,   4,  16,  39,  92,  24,  80,  62,   5,  61,  35,  73,  99,\n",
      "         98,  83])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\georg\\OneDrive\\Documents\\IITM\\Clubs\\AI Club\\Hackathons\\doodle_detectives_model.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train(basic_cnn, train_loader, cnn_optimizer, loss_fn)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m torch\u001b[39m.\u001b[39msave(basic_cnn\u001b[39m.\u001b[39mstate_dict(), \u001b[39m'\u001b[39m\u001b[39mfirst_model.pt\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\georg\\OneDrive\\Documents\\IITM\\Clubs\\AI Club\\Hackathons\\doodle_detectives_model.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# print(targets)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()  \u001b[39m# Ensures gradients stored in optimizer are reset before each backward pass\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m loss_val\u001b[39m.\u001b[39;49mbackward() \u001b[39m# Backward pass\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep() \u001b[39m# Backward pass\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mif\u001b[39;00m ps \u001b[39mand\u001b[39;00m i \u001b[39m%\u001b[39m ps \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(basic_cnn, train_loader, cnn_optimizer, loss_fn)\n",
    "torch.save(basic_cnn.state_dict(), 'first_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "0.013020833333333334\n"
     ]
    }
   ],
   "source": [
    "val_set = MyDataset(df_val['drawing'], df_val['word'])\n",
    "val_loader = DataLoader(val_set, batch_size=128)\n",
    "print(accuracy(basic_cnn, val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = pd.read_csv('doodle-detectives-aiclubiitm/test.csv')#, dtype={'drawing': np.array})\n",
    "# dft['drawing'] = dft['drawing'].map(vector_to_numpy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 48611721216 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\georg\\OneDrive\\Documents\\IITM\\Clubs\\AI Club\\Hackathons\\doodle_detectives_model.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dataset \u001b[39m=\u001b[39m MyDataset(dft[\u001b[39m'\u001b[39;49m\u001b[39mdrawing\u001b[39;49m\u001b[39m'\u001b[39;49m], np\u001b[39m.\u001b[39;49mzeros(\u001b[39mlen\u001b[39;49m(dft)))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m dataloader \u001b[39m=\u001b[39m DataLoader(dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, drop_last\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\georg\\OneDrive\\Documents\\IITM\\Clubs\\AI Club\\Hackathons\\doodle_detectives_model.ipynb Cell 14\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X22sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, data, targets):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X22sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(data, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat32)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X22sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(le\u001b[39m.\u001b[39mfit_transform(targets\u001b[39m.\u001b[39mvalues), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 48611721216 bytes."
     ]
    }
   ],
   "source": [
    "test_dataset = MyDataset(dft['drawing'], train=False, ids=dft['key_id'])\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cnn.load_state_dict(torch.load('first_model.pt'))\n",
    "basic_cnn.predict(test_loader)\n",
    "# basic_cnn.eval()\n",
    "# with torch.no_grad():\n",
    "#     count = 0\n",
    "#     correct = 0\n",
    "#     for data, targets in iter(dataloader):\n",
    "#         outputs = model.forward(data)\n",
    "#         predicted = outputs.max(1)[1] # Maximum output is predicted class\n",
    "#         count += len(targets) # Total length of datasetS\n",
    "#         correct += (predicted == targets).sum().item()\n",
    "#         # This gives a tensor of True and False values and adds no. of True values to correct each iteration\n",
    "#     print((predicted == targets).sum().item())\n",
    "#     accuracy = correct/count\n",
    "#     return accuracy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
