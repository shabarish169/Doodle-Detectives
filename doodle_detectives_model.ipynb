{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def vector_to_numpy(drawing, side=256):\n",
    "    image = vector_to_image(drawing, side)\n",
    "    image_array = np.array(image)\n",
    "    return image_array\n",
    "\n",
    "def vector_to_image(drawing, side=256):\n",
    "    drawing = json.loads(drawing)\n",
    "    min_x, min_y, max_x, max_y = calculate_bounding_box(drawing)\n",
    "\n",
    "    # Calculate the offset to center the drawing within the canvas\n",
    "    offset_x = (side - (max_x - min_x + 1)) // 2\n",
    "    offset_y = (side - (max_y - min_y + 1)) // 2\n",
    "\n",
    "    image = Image.new('L', (side, side), color='white')  # Create a white canvas\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for x, y in drawing:\n",
    "        xy = [(x0 - min_x + offset_x, y0 - min_y + offset_y) for x0, y0 in zip(x, y)]\n",
    "        draw.line(xy, fill='black', width=1)\n",
    "\n",
    "    return image\n",
    "\n",
    "def calculate_bounding_box(drawing):\n",
    "    all_x = [x for x, _ in drawing]\n",
    "    all_y = [y for _, y in drawing]\n",
    "\n",
    "    min_x = min(min(x) for x in all_x)\n",
    "    min_y = min(min(y) for y in all_y)\n",
    "    max_x = max(max(x) for x in all_x)\n",
    "    max_y = max(max(y) for y in all_y)\n",
    "\n",
    "    return min_x, min_y, max_x, max_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('doodle-detectives-aiclubiitm/train.csv')#, dtype={'drawing': np.array})\n",
    "class_list = df['word'].unique()\n",
    "classes = {word: index for index, word in enumerate(class_list)}\n",
    "def prediction_to_words(prediction):\n",
    "    return ' '.join((class_list[p] for p in prediction))\n",
    "# df['drawing'] = df['drawing'].map(vector_to_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            # 1 input image. If we had an RGB image, it would be Conv2d(3, 32, 3, padding=1)\n",
    "            # 32 output images, i.e, 32 kernels and 32 output images are produced\n",
    "            nn.ReLU(),\n",
    "            # The activation function\n",
    "            nn.MaxPool2d(4),\n",
    "            # Pooling with 2 x 2 blocks\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            # Now we have those 32 images and we make 64 from them\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4)\n",
    "            # Pooling again\n",
    "        )\n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear((256*256*64)//256, 600),\n",
    "            # The image shape was initially 28 x 28, by pooling we've made it 7 x 7, so we divide by 16\n",
    "            # We multiply by 64 because the model has learnt 64 features.\n",
    "            nn.Linear(600, 128),\n",
    "            nn.Linear(128, 101)\n",
    "            # We have 10 output neurons (1 for each class)\n",
    "        )\n",
    "    def forward(self, inputs):\n",
    "        # inputs = inputs.reshape([inputs.shape[1], inputs.shape[0], 256, 256])\n",
    "        # print(type(inputs))\n",
    "        x = self.convolutions(inputs)\n",
    "        # Functions in convolution layers are run\n",
    "        x = self.fully_connected(x)\n",
    "        # Functions in fully connected layer are run\n",
    "        return x\n",
    "    def predict(self, test_loader, out='SUBMISSION.csv', out_small='sub', i_0=0): # out = None may not be implemented\n",
    "        \"\"\"\n",
    "        Returns the predictions in a csv chosen by out, i_0 is in case you crash and have already done some stuff\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        if not out: total_predictions=[]\n",
    "        for i, (data, ids) in enumerate(iter(test_loader)):\n",
    "            if i_0 > i: continue\n",
    "            predictions = torch.topk(self.forward(data), 3, dim=1)[1]\n",
    "            predictions = (prediction_to_words(p) for p in predictions)\n",
    "            if out:\n",
    "                df = pd.DataFrame({'key_id': ids, 'word': predictions})# dtype={'key_id': np.int64, 'word': np.array})\n",
    "                # df['predictions'] = df['predictions'].map(prediction_to_words)\n",
    "                df.to_csv(f'{out_small}_{i}.csv', index=False)\n",
    "            else: total_predictions.append(predictions)\n",
    "        if not out: return total_predictions\n",
    "        else:\n",
    "            total_predictions = []\n",
    "            for j in range(i+1):\n",
    "                total_predictions.append(pd.read_csv(f'{out_small}_{j}.csv'))\n",
    "            total_predictions = pd.concat(total_predictions)\n",
    "            total_predictions.to_csv(out, index=False)\n",
    "\n",
    "# le = preprocessing.LabelEncoder()\n",
    "class MyDataset():\n",
    "    def __init__(self, data, targets=None, ids=None, train=True):\n",
    "        self.data = data\n",
    "        self.train = train\n",
    "        if train: \n",
    "            self.targets = targets.map(lambda target: classes[target])\n",
    "        if ids is not None: self.ids = ids\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, i):\n",
    "        img = vector_to_numpy(self.data.loc[i])\n",
    "        if self.train: return (torch.tensor(img, dtype=torch.float32).reshape((1, *img.shape))), torch.tensor(self.targets[i], dtype=torch.int64)\n",
    "        if self.ids is not None: return (torch.tensor(img, dtype=torch.float32).reshape((1, *img.shape))), torch.tensor(self.ids[i], dtype=torch.int64)\n",
    "        return (torch.tensor(img, dtype=torch.float32).reshape(1, *img.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining one epoch of training\n",
    "def train(model, train_loader, optimizer, loss, ps=50):\n",
    "    # We train the appropriate model with the input data and the appropriate optimizer\n",
    "    # ps is how often we print the accuracy\n",
    "    train_iter = iter(train_loader)\n",
    "    model.train()\n",
    "    # Puts model in train mode\n",
    "    for i, (data, targets) in enumerate(train_iter):\n",
    "        # i is iteration, data = 1 mini batch of images, targets = 1 mini batch target values\n",
    "        # This repeats for all mini batches \n",
    "        # print(targets)\n",
    "        outputs = model.forward(data) # Forward pass\n",
    "        loss_val = loss(outputs, targets) # Loss computation\n",
    "        # print(targets)\n",
    "        optimizer.zero_grad()  # Ensures gradients stored in optimizer are reset before each backward pass\n",
    "        loss_val.backward() # Backward pass\n",
    "        optimizer.step() # Backward pass\n",
    "\n",
    "        if ps and i % ps == 0:\n",
    "            model.eval()\n",
    "            # Puts model in evaluation mode, so we \n",
    "            with torch.no_grad():\n",
    "                print(f\"Loss is {loss_val}\")\n",
    "                predicted = outputs.max(1)[1]\n",
    "                correct = (predicted == targets).sum().item()\n",
    "                accuracy = correct/len(targets)\n",
    "                print(f\"Train accuracy is {accuracy*100:.3f}%\")\n",
    "def accuracy(model, test):\n",
    "    # Evaluate a model given a test loader\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        count = 0\n",
    "        correct = 0\n",
    "        for data, targets in iter(test):\n",
    "            outputs = model.forward(data)\n",
    "            predicted = outputs.max(1)[1] # Maximum output is predicted class\n",
    "            count += len(targets) # Total length of datasetS\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            # This gives a tensor of True and False values and adds no. of True values to correct each iteration\n",
    "        print((predicted == targets).sum().item())\n",
    "        accuracy = correct/count\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cnn = BasicCNN()\n",
    "cnn_optimizer = torch.optim.Adam(basic_cnn.parameters(), lr=2e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, val_index in StratifiedKFold(n_splits=5).split(df['drawing'], df['word']):\n",
    "    df_train = df.loc[train_index].reset_index().drop('index', axis=1)\n",
    "    df_val = df.loc[val_index].reset_index().drop('index', axis=1)\n",
    "    break\n",
    "train_dataset = MyDataset(df_train['drawing'], df_train['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(next(iter(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drawing</th>\n",
       "      <th>key_id</th>\n",
       "      <th>word</th>\n",
       "      <th>recognized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[42, 15, 4, 1, 0, 6, 14, 24, 70, 72, 58, 51,...</td>\n",
       "      <td>6077534540136448</td>\n",
       "      <td>headphones</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[92, 96, 111, 147, 183, 211, 225, 238, 238, ...</td>\n",
       "      <td>6466812659105792</td>\n",
       "      <td>headphones</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[11, 8, 15, 45, 69, 81, 99, 107, 87, 52, 43,...</td>\n",
       "      <td>5836209777541120</td>\n",
       "      <td>headphones</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[39, 42, 56, 81, 93, 100, 115, 150, 166, 167...</td>\n",
       "      <td>6335595888508928</td>\n",
       "      <td>headphones</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[48, 62, 83, 129, 160, 184, 208, 216, 228], ...</td>\n",
       "      <td>5763670711730176</td>\n",
       "      <td>headphones</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346082</th>\n",
       "      <td>[[[78, 73, 73, 77, 86, 94, 108, 122, 130, 129,...</td>\n",
       "      <td>4965983666044928</td>\n",
       "      <td>mermaid</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346083</th>\n",
       "      <td>[[[223, 168, 119, 106, 55, 33, 20, 0, 13, 28, ...</td>\n",
       "      <td>5232698266222592</td>\n",
       "      <td>leg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346084</th>\n",
       "      <td>[[[74, 65, 60, 57, 64, 74, 78, 81, 91, 128, 14...</td>\n",
       "      <td>4509987894198272</td>\n",
       "      <td>teddy-bear</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346085</th>\n",
       "      <td>[[[135, 106, 91, 69, 60, 31, 9, 1, 1, 14, 49, ...</td>\n",
       "      <td>4673679432613888</td>\n",
       "      <td>mermaid</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346086</th>\n",
       "      <td>[[[226, 191, 128, 66, 55, 44, 4, 0, 2, 49, 56,...</td>\n",
       "      <td>6144803123232768</td>\n",
       "      <td>whale</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>346087 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  drawing            key_id  \\\n",
       "0       [[[42, 15, 4, 1, 0, 6, 14, 24, 70, 72, 58, 51,...  6077534540136448   \n",
       "1       [[[92, 96, 111, 147, 183, 211, 225, 238, 238, ...  6466812659105792   \n",
       "2       [[[11, 8, 15, 45, 69, 81, 99, 107, 87, 52, 43,...  5836209777541120   \n",
       "3       [[[39, 42, 56, 81, 93, 100, 115, 150, 166, 167...  6335595888508928   \n",
       "4       [[[48, 62, 83, 129, 160, 184, 208, 216, 228], ...  5763670711730176   \n",
       "...                                                   ...               ...   \n",
       "346082  [[[78, 73, 73, 77, 86, 94, 108, 122, 130, 129,...  4965983666044928   \n",
       "346083  [[[223, 168, 119, 106, 55, 33, 20, 0, 13, 28, ...  5232698266222592   \n",
       "346084  [[[74, 65, 60, 57, 64, 74, 78, 81, 91, 128, 14...  4509987894198272   \n",
       "346085  [[[135, 106, 91, 69, 60, 31, 9, 1, 1, 14, 49, ...  4673679432613888   \n",
       "346086  [[[226, 191, 128, 66, 55, 44, 4, 0, 2, 49, 56,...  6144803123232768   \n",
       "\n",
       "              word  recognized  \n",
       "0       headphones        True  \n",
       "1       headphones        True  \n",
       "2       headphones        True  \n",
       "3       headphones       False  \n",
       "4       headphones       False  \n",
       "...            ...         ...  \n",
       "346082     mermaid       False  \n",
       "346083         leg       False  \n",
       "346084  teddy-bear       False  \n",
       "346085     mermaid        True  \n",
       "346086       whale        True  \n",
       "\n",
       "[346087 rows x 4 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_loader.targets.loc[0]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 18.203947067260742\n",
      "Train accuracy is 0.781%\n",
      "Loss is 4.623004913330078\n",
      "Train accuracy is 0.781%\n",
      "Loss is 4.624817371368408\n",
      "Train accuracy is 1.562%\n",
      "Loss is 4.616598129272461\n",
      "Train accuracy is 0.000%\n",
      "Loss is 4.61565637588501\n",
      "Train accuracy is 0.781%\n",
      "Loss is 4.6077094078063965\n",
      "Train accuracy is 3.125%\n",
      "Loss is 4.612713813781738\n",
      "Train accuracy is 2.344%\n",
      "Loss is 4.612171173095703\n",
      "Train accuracy is 0.000%\n",
      "Loss is 4.622580528259277\n",
      "Train accuracy is 0.781%\n",
      "Loss is 4.619567394256592\n",
      "Train accuracy is 0.781%\n",
      "Loss is 4.615414619445801\n",
      "Train accuracy is 2.344%\n",
      "Loss is 4.612818717956543\n",
      "Train accuracy is 4.688%\n",
      "Loss is 4.61730432510376\n",
      "Train accuracy is 0.781%\n",
      "Loss is 4.600606918334961\n",
      "Train accuracy is 0.781%\n",
      "Loss is 4.620156288146973\n",
      "Train accuracy is 1.562%\n",
      "Loss is 4.616125106811523\n",
      "Train accuracy is 0.000%\n",
      "Loss is 4.612092971801758\n",
      "Train accuracy is 0.781%\n",
      "Loss is 4.6301703453063965\n",
      "Train accuracy is 0.781%\n",
      "Loss is 4.600183486938477\n",
      "Train accuracy is 0.781%\n",
      "Loss is 4.605968475341797\n",
      "Train accuracy is 2.344%\n",
      "Loss is 4.606321811676025\n",
      "Train accuracy is 0.781%\n",
      "Loss is 4.617122173309326\n",
      "Train accuracy is 0.781%\n",
      "Loss is 4.601974964141846\n",
      "Train accuracy is 3.125%\n",
      "Loss is 4.617536544799805\n",
      "Train accuracy is 0.781%\n",
      "Loss is 4.61626672744751\n",
      "Train accuracy is 2.344%\n",
      "Loss is 4.611245155334473\n",
      "Train accuracy is 0.781%\n",
      "Loss is 4.608982086181641\n",
      "Train accuracy is 1.562%\n",
      "Loss is 4.614739418029785\n",
      "Train accuracy is 2.344%\n",
      "Loss is 4.611049652099609\n",
      "Train accuracy is 0.781%\n",
      "Loss is 4.608311653137207\n",
      "Train accuracy is 0.000%\n",
      "Loss is 4.618139266967773\n",
      "Train accuracy is 0.781%\n",
      "Loss is 4.607131481170654\n",
      "Train accuracy is 2.344%\n",
      "Loss is 4.630618572235107\n",
      "Train accuracy is 1.562%\n",
      "Loss is 4.614833354949951\n",
      "Train accuracy is 0.000%\n",
      "Loss is 4.612674713134766\n",
      "Train accuracy is 2.344%\n",
      "Loss is 4.615697860717773\n",
      "Train accuracy is 0.000%\n",
      "Loss is 4.612717628479004\n",
      "Train accuracy is 0.781%\n",
      "Loss is 4.611623287200928\n",
      "Train accuracy is 2.344%\n",
      "Loss is 4.620491981506348\n",
      "Train accuracy is 0.781%\n",
      "Loss is 4.628533363342285\n",
      "Train accuracy is 0.781%\n",
      "Loss is 4.608973503112793\n",
      "Train accuracy is 0.781%\n",
      "Loss is 4.6262993812561035\n",
      "Train accuracy is 1.562%\n",
      "Loss is 4.614963054656982\n",
      "Train accuracy is 2.344%\n",
      "Loss is 4.6085004806518555\n",
      "Train accuracy is 2.344%\n",
      "Loss is 4.6191301345825195\n",
      "Train accuracy is 0.000%\n",
      "Loss is 4.603531360626221\n",
      "Train accuracy is 0.781%\n",
      "Loss is 4.603735446929932\n",
      "Train accuracy is 2.344%\n",
      "Loss is 4.612779140472412\n",
      "Train accuracy is 0.781%\n",
      "Loss is 4.607593059539795\n",
      "Train accuracy is 1.562%\n",
      "Loss is 4.599526882171631\n",
      "Train accuracy is 1.562%\n",
      "Loss is 4.621678352355957\n",
      "Train accuracy is 0.000%\n",
      "Loss is 4.596498966217041\n",
      "Train accuracy is 2.344%\n",
      "Loss is 4.611751556396484\n",
      "Train accuracy is 2.344%\n",
      "Loss is 4.623076438903809\n",
      "Train accuracy is 0.000%\n",
      "Loss is 4.605321407318115\n",
      "Train accuracy is 3.906%\n"
     ]
    }
   ],
   "source": [
    "train(basic_cnn, train_loader, cnn_optimizer, loss_fn)\n",
    "torch.save(basic_cnn.state_dict(), 'first_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.014239153047779755\n"
     ]
    }
   ],
   "source": [
    "val_set = MyDataset(df_val['drawing'], df_val['word'])\n",
    "val_loader = DataLoader(val_set, batch_size=128)\n",
    "print(accuracy(basic_cnn, val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = pd.read_csv('doodle-detectives-aiclubiitm/test.csv')#, dtype={'drawing': np.array})\n",
    "# dft['drawing'] = dft['drawing'].map(vector_to_numpy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MyDataset(dft['drawing'], train=False, ids=dft['key_id'])\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 22.982208251953125\n",
      "Train accuracy is 0.000%\n",
      "Loss is 23.19214630126953\n",
      "Train accuracy is 0.000%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\georg\\OneDrive\\Documents\\IITM\\Clubs\\AI Club\\Hackathons\\doodle_detectives_model.ipynb Cell 16\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m basic_cnn_2\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mfirst_model.pt\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m basic_cnn_3 \u001b[39m=\u001b[39m BasicCNN()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train(basic_cnn_3, train_loader, cnn_optimizer, loss_fn, ps\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#     print(basic_cnn_2.forward(next(iter(test_loader))[0]))\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# # basic_cnn.eval()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m#     accuracy = correct/count\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m#     return accuracy\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\georg\\OneDrive\\Documents\\IITM\\Clubs\\AI Club\\Hackathons\\doodle_detectives_model.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Puts model in train mode\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (data, targets) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_iter):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m# i is iteration, data = 1 mini batch of images, targets = 1 mini batch target values\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# This repeats for all mini batches \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m# print(targets)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(data) \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     loss_val \u001b[39m=\u001b[39m loss(outputs, targets) \u001b[39m# Loss computation\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m# print(targets)\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\georg\\OneDrive\\Documents\\IITM\\Clubs\\AI Club\\Hackathons\\doodle_detectives_model.ipynb Cell 16\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39m# inputs = inputs.reshape([inputs.shape[1], inputs.shape[0], 256, 256])\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m# print(type(inputs))\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvolutions(inputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m# Functions in convolution layers are run\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfully_connected(x)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "basic_cnn_2 = BasicCNN()\n",
    "basic_cnn_2.load_state_dict(torch.load('first_model.pt'))\n",
    "basic_cnn_3 = BasicCNN()\n",
    "train(basic_cnn_3, train_loader, cnn_optimizer, loss_fn, ps=2)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     print(basic_cnn_2.forward(next(iter(test_loader))[0]))\n",
    "# # basic_cnn.eval()\n",
    "# with torch.no_grad():\n",
    "#     count = 0\n",
    "#     correct = 0\n",
    "#     for data, targets in iter(dataloader):\n",
    "#         outputs = model.forward(data)\n",
    "#         predicted = outputs.max(1)[1] # Maximum output is predicted class\n",
    "#         count += len(targets) # Total length of datasetS\n",
    "#         correct += (predicted == targets).sum().item()\n",
    "#         # This gives a tensor of True and False values and adds no. of True values to correct each iteration\n",
    "#     print((predicted == targets).sum().item())\n",
    "#     accuracy = correct/count\n",
    "#     return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\georg\\OneDrive\\Documents\\IITM\\Clubs\\AI Club\\Hackathons\\doodle_detectives_model.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m basic_cnn_3\u001b[39m.\u001b[39;49mpredict(test_loader)\n",
      "\u001b[1;32mc:\\Users\\georg\\OneDrive\\Documents\\IITM\\Clubs\\AI Club\\Hackathons\\doodle_detectives_model.ipynb Cell 17\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X24sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (data, ids) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39miter\u001b[39m(test_loader)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X24sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     \u001b[39mif\u001b[39;00m i_0 \u001b[39m>\u001b[39m i: \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X24sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     predictions \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtopk(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(data), \u001b[39m3\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X24sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     predictions \u001b[39m=\u001b[39m (prediction_to_words(p) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m predictions)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X24sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39mif\u001b[39;00m out:\n",
      "\u001b[1;32mc:\\Users\\georg\\OneDrive\\Documents\\IITM\\Clubs\\AI Club\\Hackathons\\doodle_detectives_model.ipynb Cell 17\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X24sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X24sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39m# inputs = inputs.reshape([inputs.shape[1], inputs.shape[0], 256, 256])\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X24sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m# print(type(inputs))\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X24sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvolutions(inputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X24sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m# Functions in convolution layers are run\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X24sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfully_connected(x)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\pooling.py:166\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor):\n\u001b[1;32m--> 166\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmax_pool2d(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    167\u001b[0m                         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, ceil_mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mceil_mode,\n\u001b[0;32m    168\u001b[0m                         return_indices\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreturn_indices)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_jit_internal.py:484\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[39mreturn\u001b[39;00m if_true(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    483\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 484\u001b[0m     \u001b[39mreturn\u001b[39;00m if_false(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\functional.py:782\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[39mif\u001b[39;00m stride \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m     stride \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mannotate(List[\u001b[39mint\u001b[39m], [])\n\u001b[1;32m--> 782\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mmax_pool2d(\u001b[39minput\u001b[39;49m, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "basic_cnn_3.predict(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
