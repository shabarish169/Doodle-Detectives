{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import torchvision.models, torchvision.transforms as transforms\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def vector_to_numpy(drawing, side=256):\n",
    "    image = vector_to_image(drawing, side)\n",
    "    image_array = np.array(image)\n",
    "    return image_array\n",
    "\n",
    "def vector_to_image(drawing, side=256):\n",
    "    drawing = json.loads(drawing)\n",
    "    min_x, min_y, max_x, max_y = calculate_bounding_box(drawing)\n",
    "\n",
    "    # Calculate the offset to center the drawing within the canvas\n",
    "    offset_x = (side - (max_x - min_x + 1)) // 2\n",
    "    offset_y = (side - (max_y - min_y + 1)) // 2\n",
    "\n",
    "    image = Image.new('L', (side, side), color='white')  # Create a white canvas\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for x, y in drawing:\n",
    "        xy = [(x0 - min_x + offset_x, y0 - min_y + offset_y) for x0, y0 in zip(x, y)]\n",
    "        draw.line(xy, fill='black', width=1)\n",
    "\n",
    "    return image\n",
    "\n",
    "def calculate_bounding_box(drawing):\n",
    "    all_x = [x for x, _ in drawing]\n",
    "    all_y = [y for _, y in drawing]\n",
    "\n",
    "    min_x = min(min(x) for x in all_x)\n",
    "    min_y = min(min(y) for y in all_y)\n",
    "    max_x = max(max(x) for x in all_x)\n",
    "    max_y = max(max(y) for y in all_y)\n",
    "\n",
    "    return min_x, min_y, max_x, max_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('doodle-detectives-aiclubiitm/train.csv') #, dtype={'drawing': np.array})\n",
    "class_list = df['word'].unique()\n",
    "classes = {word: index for index, word in enumerate(class_list)}\n",
    "def prediction_to_words(prediction):\n",
    "    return ' '.join((class_list[p] for p in prediction))\n",
    "df = df.sample(n=10000).reset_index().drop('index', axis=1)\n",
    "# df['drawing'] = df['drawing'].map(vector_to_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\georg\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "    #  transforms.Resize((224, 224)),\n",
    "     transforms.Lambda(lambda x: x.repeat(1,3, 1, 1)),\n",
    "    #  transforms.Lambda(lambda x: print(x.shape)),\n",
    "    #  transforms.Grayscale(num_output_channels=3),\n",
    "    #  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "     ])\n",
    "vgg16 = torchvision.models.vgg16(weights=torchvision.models.VGG16_Weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            # 1 input image. If we had an RGB image, it would be Conv2d(3, 32, 3, padding=1)\n",
    "            # 32 output images, i.e, 32 kernels and 32 output images are produced\n",
    "            nn.ReLU(),\n",
    "            # The activation function\n",
    "            nn.MaxPool2d(4),\n",
    "            # Pooling with 2 x 2 blocks\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            # Now we have those 32 images and we make 64 from them\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4)\n",
    "            # Pooling again\n",
    "        )\n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear((224*224*64)//256, 600),\n",
    "            # The image shape was initially 28 x 28, by pooling we've made it 7 x 7, so we divide by 16\n",
    "            # We multiply by 64 because the model has learnt 64 features.\n",
    "            nn.Linear(600, 128),\n",
    "            nn.Linear(128, 101)\n",
    "            # We have 10 output neurons (1 for each class)\n",
    "        )\n",
    "    def forward(self, inputs):\n",
    "        # inputs = inputs.reshape([inputs.shape[1], inputs.shape[0], 256, 256])\n",
    "        # print(type(inputs))\n",
    "        x = self.convolutions(inputs)\n",
    "        # Functions in convolution layers are run\n",
    "        x = self.fully_connected(x)\n",
    "        # Functions in fully connected layer are run\n",
    "        return x\n",
    "    def predict(self, test_loader, out='SUBMISSION.csv', out_small='sub', i_0=0): # out = None may not be implemented\n",
    "        \"\"\"\n",
    "        Returns the predictions in a csv chosen by out, i_0 is in case you crash and have already done some stuff\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        if not out: total_predictions=[]\n",
    "        for i, (data, ids) in enumerate(iter(test_loader)):\n",
    "            if i_0 > i: continue\n",
    "            predictions = torch.topk(self.forward(data), 3, dim=1)[1]\n",
    "            predictions = (prediction_to_words(p) for p in predictions)\n",
    "            if out:\n",
    "                df = pd.DataFrame({'key_id': ids, 'word': predictions})# dtype={'key_id': np.int64, 'word': np.array})\n",
    "                # df['predictions'] = df['predictions'].map(prediction_to_words)\n",
    "                df.to_csv(f'{out_small}_{i}.csv', index=False)\n",
    "            else: total_predictions.append(predictions)\n",
    "        if not out: return total_predictions\n",
    "        else:\n",
    "            total_predictions = []\n",
    "            for j in range(i+1):\n",
    "                total_predictions.append(pd.read_csv(f'{out_small}_{j}.csv'))\n",
    "            total_predictions = pd.concat(total_predictions)\n",
    "            total_predictions.to_csv(out, index=False)\n",
    "\n",
    "# le = preprocessing.LabelEncoder()\n",
    "class MyDataset():\n",
    "    def __init__(self, data, targets=None, ids=None, train=True):\n",
    "        self.data = data\n",
    "        self.train = train\n",
    "        if train: \n",
    "            self.targets = targets.map(lambda target: classes[target])\n",
    "        if ids is not None: self.ids = ids\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, i):\n",
    "        img = 1 - vector_to_numpy(self.data.loc[i], side=224)//255\n",
    "        if self.train: return (torch.tensor(img, dtype=torch.float32).reshape((1, *img.shape))), torch.tensor(self.targets[i], dtype=torch.int64)\n",
    "        if self.ids is not None: return (torch.tensor(img, dtype=torch.float32).reshape((1, *img.shape))), torch.tensor(self.ids[i], dtype=torch.int64)\n",
    "        return (torch.tensor(img, dtype=torch.float32).reshape((1, *img.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "vgg_length = len(list(vgg16.features.parameters()))\n",
    "for param in vgg16.features.parameters():\n",
    "    if i < vgg_length - 2: param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "        self.convolutions = vgg16\n",
    "        self.extra = nn.Sequential(\n",
    "            nn.Linear(1000, 101), # This was my 1st guess at the no of outputs in VGG16, I was so surprised when it worked\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    def forward(self, inputs):\n",
    "        # inputs = inputs.reshape([inputs.shape[1], inputs.shape[0], 256, 256])\n",
    "        # print(type(inputs))\n",
    "        inputs = transform(inputs).to(device=device)\n",
    "        x = self.convolutions(inputs)\n",
    "        x = self.extra(x)\n",
    "        # Functions in fully connected layer are run\n",
    "        return x\n",
    "    def predict(self, test_loader, out='SUBMISSION.csv', out_small='sub', i_0=0): # out = None may not be implemented\n",
    "        \"\"\"\n",
    "        Returns the predictions in a csv chosen by out, i_0 is in case you crash and have already done some stuff\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        if not out: total_predictions=[]\n",
    "        for i, (data, ids) in enumerate(iter(test_loader)):\n",
    "            if i_0 > i: continue\n",
    "            predictions = torch.topk(self.forward(data), 3, dim=1)[1]\n",
    "            predictions = (prediction_to_words(p) for p in predictions)\n",
    "            if out:\n",
    "                df = pd.DataFrame({'key_id': ids, 'word': predictions})# dtype={'key_id': np.int64, 'word': np.array})\n",
    "                # df['predictions'] = df['predictions'].map(prediction_to_words)\n",
    "                df.to_csv(f'{out_small}_{i}.csv', index=False)\n",
    "            else: total_predictions.append(predictions)\n",
    "        if not out: return total_predictions\n",
    "        else:\n",
    "            total_predictions = []\n",
    "            for j in range(i+1):\n",
    "                total_predictions.append(pd.read_csv(f'{out_small}_{j}.csv'))\n",
    "            total_predictions = pd.concat(total_predictions)\n",
    "            total_predictions.to_csv(out, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining one epoch of training\n",
    "def train(model, train_loader, optimizer, loss, ps=50):\n",
    "    # We train the appropriate model with the input data and the appropriate optimizer\n",
    "    # ps is how often we print the accuracy\n",
    "    train_iter = iter(train_loader)\n",
    "    model.train()\n",
    "    # Puts model in train mode\n",
    "    for i, (data, targets) in enumerate(train_iter):\n",
    "        # i is iteration, data = 1 mini batch of images, targets = 1 mini batch target values\n",
    "        # This repeats for all mini batches \n",
    "        # print(targets)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model.forward(data) # Forward pass\n",
    "        loss_val = loss(outputs, targets) # Loss computation\n",
    "        # print(targets)\n",
    "        optimizer.zero_grad()  # Ensures gradients stored in optimizer are reset before each backward pass\n",
    "        loss_val.backward() # Backward pass\n",
    "        optimizer.step() # Backward pass\n",
    "\n",
    "        if ps and i % ps == 0:\n",
    "            model.eval()\n",
    "            # Puts model in evaluation mode, so we \n",
    "            with torch.no_grad():\n",
    "                print(f\"Loss is {loss_val}\")\n",
    "                predicted = outputs.max(1)[1]\n",
    "                correct = (predicted == targets).sum().item()\n",
    "                accuracy = correct/len(targets)\n",
    "                print(f\"Train accuracy is {accuracy*100:.3f}%\")\n",
    "def accuracy(model, test):\n",
    "    # Evaluate a model given a test loader\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        count = 0\n",
    "        correct = 0\n",
    "        for data, targets in iter(test):\n",
    "            targets = targets.to(device)\n",
    "            outputs = model.forward(data)\n",
    "            predicted = outputs.max(1)[1] # Maximum output is predicted class\n",
    "            count += len(targets) # Total length of datasetS\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            # This gives a tensor of True and False values and adds no. of True values to correct each iteration\n",
    "        # print((predicted == targets).sum().item())\n",
    "        accuracy = correct/count\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cnn = BasicCNN()\n",
    "cnn_optimizer = torch.optim.Adam(basic_cnn.parameters(), lr=2e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, val_index in KFold(n_splits=5).split(df['drawing'], df['word']):\n",
    "    df_train = df.loc[train_index].reset_index().drop('index', axis=1)\n",
    "    df_val = df.loc[val_index].reset_index().drop('index', axis=1)\n",
    "    break\n",
    "train_dataset = MyDataset(df_train['drawing'], df_train['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(next(iter(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drawing</th>\n",
       "      <th>key_id</th>\n",
       "      <th>word</th>\n",
       "      <th>recognized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[255, 137, 0], [0, 82, 214]]]</td>\n",
       "      <td>5940930873917440</td>\n",
       "      <td>lightning</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[24, 70, 75, 74, 66, 26, 163, 255, 228, 211,...</td>\n",
       "      <td>6284814711783424</td>\n",
       "      <td>pillow</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[3, 3, 37, 110, 146, 120, 53, 31, 0], [53, 2...</td>\n",
       "      <td>5973976620728320</td>\n",
       "      <td>lightning</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[80, 72, 51, 36, 19, 6, 1, 0, 9, 16, 34, 82,...</td>\n",
       "      <td>6722227842056192</td>\n",
       "      <td>apple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[1, 27, 57, 99, 136, 196, 175, 149, 116, 98,...</td>\n",
       "      <td>5491753161326592</td>\n",
       "      <td>pillow</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>[[[69, 71, 80], [129, 176, 255]], [[82, 77, 76...</td>\n",
       "      <td>5642310320652288</td>\n",
       "      <td>sword</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>[[[13, 0], [99, 155]], [[83, 66], [117, 184]],...</td>\n",
       "      <td>6698949417107456</td>\n",
       "      <td>bed</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>[[[74, 55, 49, 50, 59, 65, 74, 102, 121, 159, ...</td>\n",
       "      <td>6553356954763264</td>\n",
       "      <td>elephant</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>[[[15, 8, 1], [22, 43, 100]], [[7, 24, 15], [6...</td>\n",
       "      <td>6261791757697024</td>\n",
       "      <td>helmet</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>[[[48, 31, 23, 6, 0, 0, 5, 27, 62, 93, 120, 12...</td>\n",
       "      <td>4717168056860672</td>\n",
       "      <td>potato</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                drawing            key_id  \\\n",
       "0                       [[[255, 137, 0], [0, 82, 214]]]  5940930873917440   \n",
       "1     [[[24, 70, 75, 74, 66, 26, 163, 255, 228, 211,...  6284814711783424   \n",
       "2     [[[3, 3, 37, 110, 146, 120, 53, 31, 0], [53, 2...  5973976620728320   \n",
       "3     [[[80, 72, 51, 36, 19, 6, 1, 0, 9, 16, 34, 82,...  6722227842056192   \n",
       "4     [[[1, 27, 57, 99, 136, 196, 175, 149, 116, 98,...  5491753161326592   \n",
       "...                                                 ...               ...   \n",
       "7995  [[[69, 71, 80], [129, 176, 255]], [[82, 77, 76...  5642310320652288   \n",
       "7996  [[[13, 0], [99, 155]], [[83, 66], [117, 184]],...  6698949417107456   \n",
       "7997  [[[74, 55, 49, 50, 59, 65, 74, 102, 121, 159, ...  6553356954763264   \n",
       "7998  [[[15, 8, 1], [22, 43, 100]], [[7, 24, 15], [6...  6261791757697024   \n",
       "7999  [[[48, 31, 23, 6, 0, 0, 5, 27, 62, 93, 120, 12...  4717168056860672   \n",
       "\n",
       "           word  recognized  \n",
       "0     lightning        True  \n",
       "1        pillow       False  \n",
       "2     lightning       False  \n",
       "3         apple        True  \n",
       "4        pillow       False  \n",
       "...         ...         ...  \n",
       "7995      sword       False  \n",
       "7996        bed       False  \n",
       "7997   elephant       False  \n",
       "7998     helmet       False  \n",
       "7999     potato        True  \n",
       "\n",
       "[8000 rows x 4 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_loader.targets.loc[0]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(basic_cnn, train_loader, cnn_optimizer, loss_fn)\n",
    "# torch.save(basic_cnn.state_dict(), 'first_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = MyDataset(df_val['drawing'], df_val['word'])\n",
    "val_loader = DataLoader(val_set, batch_size=128)\n",
    "# print(accuracy(basic_cnn, val_loader))/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = pd.read_csv('doodle-detectives-aiclubiitm/test.csv')#, dtype={'drawing': np.array})\n",
    "# dft['drawing'] = dft['drawing'].map(vector_to_numpy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MyDataset(dft['drawing'], train=False, ids=dft['key_id'])\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = VGG16()\n",
    "vgg16_model.to(device)\n",
    "vgg16_optim = torch.optim.Adam(vgg16_model.parameters(), lr=2e-3)\n",
    "vgg_loss = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 4.616662979125977\n",
      "Train accuracy is 0.781%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\georg\\OneDrive\\Documents\\IITM\\Clubs\\AI Club\\Hackathons\\doodle_detectives_model.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train(vgg16_model, train_loader, vgg16_optim, vgg_loss)\n",
      "\u001b[1;32mc:\\Users\\georg\\OneDrive\\Documents\\IITM\\Clubs\\AI Club\\Hackathons\\doodle_detectives_model.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X31sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# print(targets)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X31sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()  \u001b[39m# Ensures gradients stored in optimizer are reset before each backward pass\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X31sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m loss_val\u001b[39m.\u001b[39;49mbackward() \u001b[39m# Backward pass\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X31sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep() \u001b[39m# Backward pass\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X31sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mif\u001b[39;00m ps \u001b[39mand\u001b[39;00m i \u001b[39m%\u001b[39m ps \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(vgg16_model, train_loader, vgg16_optim, vgg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model.predict(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0115\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(vgg16_model, val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\georg\\OneDrive\\Documents\\IITM\\Clubs\\AI Club\\Hackathons\\doodle_detectives_model.ipynb Cell 16\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m basic_cnn_2 \u001b[39m=\u001b[39m BasicCNN()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m basic_cnn_2\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mfirst_model.pt\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m basic_cnn_2\u001b[39m.\u001b[39;49mpredict(test_loader)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m basic_cnn_3 \u001b[39m=\u001b[39m BasicCNN()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# train(basic_cnn_3, train_loader, cnn_optimizer, loss_fn, ps=2)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m#     accuracy = correct/count\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m#     return accuracy\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\georg\\OneDrive\\Documents\\IITM\\Clubs\\AI Club\\Hackathons\\doodle_detectives_model.ipynb Cell 16\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (data, ids) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39miter\u001b[39m(test_loader)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     \u001b[39mif\u001b[39;00m i_0 \u001b[39m>\u001b[39m i: \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     predictions \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtopk(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(data), \u001b[39m3\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     predictions \u001b[39m=\u001b[39m (prediction_to_words(p) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m predictions)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39mif\u001b[39;00m out:\n",
      "\u001b[1;32mc:\\Users\\georg\\OneDrive\\Documents\\IITM\\Clubs\\AI Club\\Hackathons\\doodle_detectives_model.ipynb Cell 16\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39m# inputs = inputs.reshape([inputs.shape[1], inputs.shape[0], 256, 256])\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m# print(type(inputs))\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvolutions(inputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m# Functions in convolution layers are run\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X21sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfully_connected(x)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\activation.py:103\u001b[0m, in \u001b[0;36mReLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\functional.py:1457\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1455\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu_(\u001b[39minput\u001b[39m)\n\u001b[0;32m   1456\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m   1458\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "basic_cnn_2 = BasicCNN()\n",
    "basic_cnn_2.load_state_dict(torch.load('first_model.pt'))\n",
    "basic_cnn_2.predict(test_loader)\n",
    "basic_cnn_3 = BasicCNN()\n",
    "# train(basic_cnn_3, train_loader, cnn_optimizer, loss_fn, ps=2)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     print(basic_cnn_2.forward(next(iter(test_loader))[0]))\n",
    "# # basic_cnn.eval()\n",
    "# with torch.no_grad():\n",
    "#     count = 0\n",
    "#     correct = 0\n",
    "#     for data, targets in iter(dataloader):\n",
    "#         outputs = model.forward(data)\n",
    "#         predicted = outputs.max(1)[1] # Maximum output is predicted class\n",
    "#         count += len(targets) # Total length of datasetS\n",
    "#         correct += (predicted == targets).sum().item()\n",
    "#         # This gives a tensor of True and False values and adds no. of True values to correct each iteration\n",
    "#     print((predicted == targets).sum().item())\n",
    "#     accuracy = correct/count\n",
    "#     return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\georg\\OneDrive\\Documents\\IITM\\Clubs\\AI Club\\Hackathons\\doodle_detectives_model.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m basic_cnn_3\u001b[39m.\u001b[39;49mpredict(test_loader)\n",
      "\u001b[1;32mc:\\Users\\georg\\OneDrive\\Documents\\IITM\\Clubs\\AI Club\\Hackathons\\doodle_detectives_model.ipynb Cell 17\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X24sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (data, ids) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39miter\u001b[39m(test_loader)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X24sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     \u001b[39mif\u001b[39;00m i_0 \u001b[39m>\u001b[39m i: \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X24sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     predictions \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtopk(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(data), \u001b[39m3\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X24sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     predictions \u001b[39m=\u001b[39m (prediction_to_words(p) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m predictions)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X24sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39mif\u001b[39;00m out:\n",
      "\u001b[1;32mc:\\Users\\georg\\OneDrive\\Documents\\IITM\\Clubs\\AI Club\\Hackathons\\doodle_detectives_model.ipynb Cell 17\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X24sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X24sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39m# inputs = inputs.reshape([inputs.shape[1], inputs.shape[0], 256, 256])\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X24sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m# print(type(inputs))\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X24sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvolutions(inputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X24sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m# Functions in convolution layers are run\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/georg/OneDrive/Documents/IITM/Clubs/AI%20Club/Hackathons/doodle_detectives_model.ipynb#X24sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfully_connected(x)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# basic_cnn_3.predict(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
