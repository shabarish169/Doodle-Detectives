{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np, pandas as pd, matplotlib.pyplot as plt\nimport torch, torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import StratifiedKFold, KFold\nimport torchvision.models, torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\ntorch.manual_seed(0)\nnp.random.seed(0)\n\ndevice = torch.device('cuda')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:23.710655Z","iopub.execute_input":"2023-09-13T19:27:23.711000Z","iopub.status.idle":"2023-09-13T19:27:23.950345Z","shell.execute_reply.started":"2023-09-13T19:27:23.710973Z","shell.execute_reply":"2023-09-13T19:27:23.946334Z"},"trusted":true},"execution_count":3,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/__init__.py:457\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(textwrap\u001b[38;5;241m.\u001b[39mdedent(\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124m            Failed to load PyTorch C extensions:\u001b[39m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;124m                It appears that PyTorch has loaded the `torch/_C` folder\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;124m                or by running Python from a different directory.\u001b[39m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'''\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m  \u001b[38;5;66;03m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[39;00m\n\u001b[0;32m--> 457\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(\u001b[43m_C\u001b[49m):\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBase\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    459\u001b[0m         __all__\u001b[38;5;241m.\u001b[39mappend(name)\n","\u001b[0;31mNameError\u001b[0m: name '_C' is not defined"],"ename":"NameError","evalue":"name '_C' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# import gc\n# gc.collect()\n# torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:23.951008Z","iopub.status.idle":"2023-09-13T19:27:23.951340Z","shell.execute_reply.started":"2023-09-13T19:27:23.951179Z","shell.execute_reply":"2023-09-13T19:27:23.951194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image, ImageDraw\nimport numpy as np\nimport json\n\ndef vector_to_numpy(drawing, side=256):\n    image = vector_to_image(drawing, side)\n    image_array = np.array(image)\n    return image_array\n\ndef vector_to_image(drawing, side=256):\n    drawing = json.loads(drawing)\n    min_x, min_y, max_x, max_y = calculate_bounding_box(drawing)\n\n    # Calculate the offset to center the drawing within the canvas\n    offset_x = (side - (max_x - min_x + 1)) // 2\n    offset_y = (side - (max_y - min_y + 1)) // 2\n\n    image = Image.new('L', (side, side), color='white')  # Create a white canvas\n    draw = ImageDraw.Draw(image)\n\n    for x, y in drawing:\n        xy = [(x0 - min_x + offset_x, y0 - min_y + offset_y) for x0, y0 in zip(x, y)]\n        draw.line(xy, fill='black', width=1)\n\n    return image\n\ndef calculate_bounding_box(drawing):\n    all_x = [x for x, _ in drawing]\n    all_y = [y for _, y in drawing]\n\n    min_x = min(min(x) for x in all_x)\n    min_y = min(min(y) for y in all_y)\n    max_x = max(max(x) for x in all_x)\n    max_y = max(max(y) for y in all_y)\n\n    return min_x, min_y, max_x, max_y","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:23.953591Z","iopub.status.idle":"2023-09-13T19:27:23.954046Z","shell.execute_reply.started":"2023-09-13T19:27:23.953812Z","shell.execute_reply":"2023-09-13T19:27:23.953843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/doodle-detectives-aiclubiitm/train.csv') #, dtype={'drawing': np.array})\nclass_list = df['word'].unique()\nclasses = {word: index for index, word in enumerate(class_list)}\ndef prediction_to_words(prediction):\n    return ' '.join((class_list[p] for p in prediction))\ndf = df[df['recognized']==True].sample(n=100_000).reset_index().drop('index', axis=1)\n# df = df[df['word'].isin(class_list[:10])].reset_index().drop('index', axis=1)\n# df['drawing'] = df['drawing'].map(vector_to_numpy)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:23.956037Z","iopub.status.idle":"2023-09-13T19:27:23.957031Z","shell.execute_reply.started":"2023-09-13T19:27:23.956798Z","shell.execute_reply":"2023-09-13T19:27:23.956821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(classes, class_list, sep='\\n')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:23.958171Z","iopub.status.idle":"2023-09-13T19:27:23.958944Z","shell.execute_reply.started":"2023-09-13T19:27:23.958711Z","shell.execute_reply":"2023-09-13T19:27:23.958734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose(\n    [\n#      transforms.Resize((28, 28)),\n     transforms.Lambda(lambda x: x.repeat(1,3, 1, 1)),\n    #  transforms.Lambda(lambda x: print(x.shape)),\n    #  transforms.Grayscale(num_output_channels=3),\n    #  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n     ])\nvgg16 = torchvision.models.vgg16(weights=torchvision.models.VGG16_Weights.DEFAULT)\n# inception_v3 = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\ninception_v3 = torchvision.models.inception_v3(weights=torchvision.models.Inception_V3_Weights.DEFAULT)\ninception_v3.aux_logits = False\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:23.960470Z","iopub.status.idle":"2023-09-13T19:27:23.961037Z","shell.execute_reply.started":"2023-09-13T19:27:23.960805Z","shell.execute_reply":"2023-09-13T19:27:23.960826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BasicCNN(nn.Module):\n    def __init__(self):\n        nn.Module.__init__(self)\n        self.convolutions = nn.Sequential(\n            nn.MaxPool2d(8),\n            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n            # 1 input image. If we had an RGB image, it would be Conv2d(3, 32, 3, padding=1)\n            # 32 output images, i.e, 32 kernels and 32 output images are produced\n            nn.ReLU(),\n            # The activation function\n            nn.MaxPool2d(2),\n            # Pooling with 2 x 2 blocks\n            nn.Conv2d(32, 64, 3, padding=1),\n            # Now we have those 32 images and we make 64 from them\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n            # Pooling again\n        )\n        self.fully_connected = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear((28*28*64)//16, 512),\n            # The image shape was initially 28 x 28, by pooling we've made it 7 x 7, so we divide by 16\n            # We multiply by 64 because the model has learnt 64 features.\n            nn.Linear(512, 101),\n#             nn.Linear(128, 101)\n            # We have 10 output neurons (1 for each class)\n        )\n    def forward(self, inputs):\n        # inputs = inputs.reshape([inputs.shape[1], inputs.shape[0], 256, 256])\n        # print(type(inputs))\n#         inputs = transforms.Compose([transforms.Resize((28, 28))])(inputs)\n        x = self.convolutions(inputs.to(device))\n        # Functions in convolution layers are run\n        x = self.fully_connected(x)\n        # Functions in fully connected layer are run\n        return x\n    def predict(self, test_loader, out='SUBMISSION.csv', out_small='sub', i_0=0): # out = None may not be implemented\n        \"\"\"\n        Returns the predictions in a csv chosen by out, i_0 is in case you crash and have already done some stuff\n        \"\"\"\n        self.eval()\n        if not out: total_predictions=[]\n        for i, (data, ids) in enumerate(iter(test_loader)):\n            if i_0 > i: continue\n            predictions = torch.topk(self.forward(data), 3, dim=1)[1]\n            predictions = (prediction_to_words(p) for p in predictions)\n            if out:\n                df = pd.DataFrame({'key_id': ids, 'word': predictions})# dtype={'key_id': np.int64, 'word': np.array})\n                # df['predictions'] = df['predictions'].map(prediction_to_words)\n                df.to_csv(f'{out_small}_{i}.csv', index=False)\n            else: total_predictions.append(predictions)\n        if not out: return total_predictions\n        else:\n            total_predictions = []\n            for j in range(i+1):\n                total_predictions.append(pd.read_csv(f'{out_small}_{j}.csv'))\n            total_predictions = pd.concat(total_predictions)\n            total_predictions.to_csv(out, index=False)\n\n# le = preprocessing.LabelEncoder()\nclass MyDataset():\n    def __init__(self, data, targets=None, ids=None, train=True, size=224):\n        self.data = data\n        self.train = train\n        self.size = size\n        if train: \n            self.targets = targets.map(lambda target: classes[target])\n        if ids is not None: self.ids = ids\n    def __len__(self):\n        return len(self.data)\n    def __getitem__(self, i):\n        img = 1 - vector_to_numpy(self.data.loc[i], side=self.size)//250\n        if self.train: return (torch.tensor(img, dtype=torch.float32).reshape((1, *img.shape))), torch.tensor(self.targets[i], dtype=torch.int64)\n        if self.ids is not None: return (torch.tensor(img, dtype=torch.float32).reshape((1, *img.shape))), torch.tensor(self.ids[i], dtype=torch.int64)\n        return (torch.tensor(img, dtype=torch.float32).reshape((1, *img.shape)))","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:23.962739Z","iopub.status.idle":"2023-09-13T19:27:23.963616Z","shell.execute_reply.started":"2023-09-13T19:27:23.963358Z","shell.execute_reply":"2023-09-13T19:27:23.963382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 0\nvgg_length = len(list(vgg16.features.parameters()))\nfor param in vgg16.features.parameters():\n    if i < vgg_length - 4: param.requires_grad = False\ni = 0\ninc_length = len(list(inception_v3.parameters()))\nfor param in inception_v3.parameters():\n    if i < inc_length - 3: param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:23.965132Z","iopub.status.idle":"2023-09-13T19:27:23.965594Z","shell.execute_reply.started":"2023-09-13T19:27:23.965352Z","shell.execute_reply":"2023-09-13T19:27:23.965374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VGG16(nn.Module):\n    def __init__(self):\n        nn.Module.__init__(self)\n        self.convolutions = vgg16\n        self.extra = nn.Sequential(\n            nn.Linear(1000, 101), # This was my 1st guess at the no of outputs in VGG16, I was so surprised when it worked\n            nn.Softmax(dim=1)\n        )\n    def forward(self, inputs):\n        # inputs = inputs.reshape([inputs.shape[1], inputs.shape[0], 256, 256])\n        # print(type(inputs))\n        inputs = transform(inputs).to(device=device)\n        x = self.convolutions(inputs)\n        x = self.extra(x)\n        # Functions in fully connected layer are run\n        return x\n    def predict(self, test_loader, out='s.csv', out_small='sub', i_0=0): # out = None may not be implemented\n        \"\"\"\n        Returns the predictions in a csv chosen by out, i_0 is in case you crash and have already done some stuff\n        \"\"\"\n        self.eval()\n        if not out: total_predictions=[]\n        for i, (data, ids) in enumerate(iter(test_loader)):\n            if i_0 > i: continue\n            predictions = torch.topk(self.forward(data), 3, dim=1)[1]\n            predictions = (prediction_to_words(p) for p in predictions)\n            if out:\n                df = pd.DataFrame({'key_id': ids, 'word': predictions})# dtype={'key_id': np.int64, 'word': np.array})\n                # df['predictions'] = df['predictions'].map(prediction_to_words)\n                df.to_csv(f'{out_small}_{i}.csv', index=False)\n            else: total_predictions.append(predictions)\n        if not out: return total_predictions\n        else:\n            total_predictions = []\n            for j in range(i+1):\n                total_predictions.append(pd.read_csv(f'{out_small}_{j}.csv'))\n            total_predictions = pd.concat(total_predictions)\n            total_predictions.to_csv(out, index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:23.967058Z","iopub.status.idle":"2023-09-13T19:27:23.967394Z","shell.execute_reply.started":"2023-09-13T19:27:23.967226Z","shell.execute_reply":"2023-09-13T19:27:23.967242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Inception(nn.Module):\n    def __init__(self):\n        nn.Module.__init__(self)\n        self.convolutions = inception_v3\n\n        self.extra = nn.Sequential(\n            nn.Linear(1000, 101), # This was my 1st guess at the no of outputs in VGG16, I was so surprised when it worked\n            nn.Softmax(dim=1)\n        )\n    def forward(self, inputs):\n        # inputs = inputs.reshape([inputs.shape[1], inputs.shape[0], 256, 256])\n        # print(type(inputs))\n#         inputs = transform(inputs).to(device=device)\n        inputs = transforms.Compose([transforms.Resize((299, 299)),\n                                    transforms.Lambda(lambda x: x.repeat(1,3, 1, 1))])(inputs)\n        x = self.convolutions(inputs.to(device))\n        x = self.extra(x)\n        # Functions in fully connected layer are run\n        return x\n    def predict(self, test_loader, out='s.csv', out_small='sub', i_0=0): # out = None may not be implemented\n        \"\"\"\n        Returns the predictions in a csv chosen by out, i_0 is in case you crash and have already done some stuff\n        \"\"\"\n        self.eval()\n        if not out: total_predictions=[]\n        for i, (data, ids) in enumerate(iter(test_loader)):\n            if i_0 > i: continue\n            predictions = torch.topk(self.forward(data), 3, dim=1)[1]\n            predictions = (prediction_to_words(p) for p in predictions)\n            if out:\n                df = pd.DataFrame({'key_id': ids, 'word': predictions})# dtype={'key_id': np.int64, 'word': np.array})\n                # df['predictions'] = df['predictions'].map(prediction_to_words)\n                df.to_csv(f'{out_small}_{i}.csv', index=False)\n            else: total_predictions.append(predictions)\n        if not out: return total_predictions\n        else:\n            total_predictions = []\n            for j in range(i+1):\n                total_predictions.append(pd.read_csv(f'{out_small}_{j}.csv'))\n            total_predictions = pd.concat(total_predictions)\n            total_predictions.to_csv(out, index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:23.969270Z","iopub.status.idle":"2023-09-13T19:27:23.969734Z","shell.execute_reply.started":"2023-09-13T19:27:23.969509Z","shell.execute_reply":"2023-09-13T19:27:23.969530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining one epoch of training\ndef train(model, train_loader, optimizer, loss, ps=50):\n    # We train the appropriate model with the input data and the appropriate optimizer\n    # ps is how often we print the accuracy\n    train_iter = iter(train_loader)\n    model.train()\n    # Puts model in train mode\n    for i, (data, targets) in enumerate(train_iter):\n        # i is iteration, data = 1 mini batch of images, targets = 1 mini batch target values\n        # This repeats for all mini batches \n        # print(targets)\n        targets = targets.to(device)\n        outputs = model.forward(data) # Forward pass\n        loss_val = loss(outputs, targets) # Loss computation\n        # print(targets)\n        optimizer.zero_grad()  # Ensures gradients stored in optimizer are reset before each backward pass\n        loss_val.backward() # Backward pass\n        optimizer.step() # Backward pass\n\n        if ps and i % ps == 0:\n            model.eval()\n            # Puts model in evaluation mode, so we \n            with torch.no_grad():\n                print(f\"Loss is {loss_val}\")\n                predicted = outputs.max(1)[1]\n                correct = (predicted == targets).sum().item()\n                accuracy = correct/len(targets)\n                print(f\"Train accuracy is {accuracy*100:.3f}%\")\ndef accuracy(model, test):\n    # Evaluate a model given a test loader\n    model.eval()\n    with torch.no_grad():\n        count = 0\n        correct = 0\n        for data, targets in iter(test):\n            targets = targets.to(device)\n            outputs = model.forward(data)\n#             predicted = outputs.max(1)[1] # Maximum output is predicted class\n            predictions = torch.topk(outputs, 3, dim=1)[1]\n            pred_1 = predictions[:, 0]\n            pred_2 = predictions[:, 1]\n            pred_3 = predictions[:, 2]\n            count += len(targets) # Total length of datasetS\n            correct += (pred_1 == targets).sum().item() + (pred_2 == targets).sum().item() + (pred_3 == targets).sum().item()\n            # This gives a tensor of True and False values and adds no. of True values to correct each iteration\n        # print((predicted == targets).sum().item())\n        accuracy = correct/count\n        return accuracy","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:23.971470Z","iopub.status.idle":"2023-09-13T19:27:23.971903Z","shell.execute_reply.started":"2023-09-13T19:27:23.971680Z","shell.execute_reply":"2023-09-13T19:27:23.971702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"basic_cnn = BasicCNN().to(device)\ncnn_optimizer = torch.optim.Adam(basic_cnn.parameters(), lr=2e-3)\nloss_fn = nn.CrossEntropyLoss().to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:23.973259Z","iopub.status.idle":"2023-09-13T19:27:23.973684Z","shell.execute_reply.started":"2023-09-13T19:27:23.973452Z","shell.execute_reply":"2023-09-13T19:27:23.973475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for train_index, val_index in KFold(n_splits=5).split(df['drawing'], df['word']):\n    df_train = df.loc[train_index].reset_index().drop('index', axis=1)\n    df_val = df.loc[val_index].reset_index().drop('index', axis=1)\n    break\ntrain_dataset = MyDataset(df_train['drawing'], df_train['word'])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:23.976161Z","iopub.status.idle":"2023-09-13T19:27:23.976747Z","shell.execute_reply.started":"2023-09-13T19:27:23.976520Z","shell.execute_reply":"2023-09-13T19:27:23.976542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:23.978325Z","iopub.status.idle":"2023-09-13T19:27:23.978915Z","shell.execute_reply.started":"2023-09-13T19:27:23.978676Z","shell.execute_reply":"2023-09-13T19:27:23.978697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(next(iter(train_loader)))","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:23.980476Z","iopub.status.idle":"2023-09-13T19:27:23.981480Z","shell.execute_reply.started":"2023-09-13T19:27:23.981235Z","shell.execute_reply":"2023-09-13T19:27:23.981257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_loader.targets.loc[0]\ndf_train","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:23.982627Z","iopub.status.idle":"2023-09-13T19:27:23.983612Z","shell.execute_reply.started":"2023-09-13T19:27:23.983362Z","shell.execute_reply":"2023-09-13T19:27:23.983385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train(basic_cnn, train_loader, cnn_optimizer, loss_fn)\ntorch.save(basic_cnn.state_dict(), 'first_model.pt')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:23.984756Z","iopub.status.idle":"2023-09-13T19:27:23.985328Z","shell.execute_reply.started":"2023-09-13T19:27:23.985099Z","shell.execute_reply":"2023-09-13T19:27:23.985119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# vgg16_model = VGG16()\n# vgg16_model.to(device)\n# vgg16_optim = torch.optim.Adam(vgg16_model.parameters(), lr=2e-3)\n# vgg_loss = nn.CrossEntropyLoss().to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:23.986871Z","iopub.status.idle":"2023-09-13T19:27:23.987639Z","shell.execute_reply.started":"2023-09-13T19:27:23.987392Z","shell.execute_reply":"2023-09-13T19:27:23.987415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# inception_v3_model = Inception()\n# inception_v3_model.to(device)\n# inc_optim = torch.optim.Adam(inception_v3_model.parameters(), lr=2e-3)\n# inc_loss = nn.CrossEntropyLoss().to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:23.989073Z","iopub.status.idle":"2023-09-13T19:27:23.990090Z","shell.execute_reply.started":"2023-09-13T19:27:23.989859Z","shell.execute_reply":"2023-09-13T19:27:23.989881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # train_dataset = MyDataset(df_train['drawing'], df_train['word'], size=299)\n# # train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n# train(inception_v3_model, train_loader, inc_optim, inc_loss)\n# torch.save(inception_v3_model.state_dict(), 'inception_v3_model.pt')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:23.991456Z","iopub.status.idle":"2023-09-13T19:27:23.991895Z","shell.execute_reply.started":"2023-09-13T19:27:23.991666Z","shell.execute_reply":"2023-09-13T19:27:23.991687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_set = MyDataset(df_val['drawing'], df_val['word'])\nval_loader = DataLoader(val_set, batch_size=128)\n# print(accuracy(basic_cnn, val_loader))/","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:23.993568Z","iopub.status.idle":"2023-09-13T19:27:23.993995Z","shell.execute_reply.started":"2023-09-13T19:27:23.993774Z","shell.execute_reply":"2023-09-13T19:27:23.993795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dft = pd.read_csv('/kaggle/input/doodle-detectives-aiclubiitm/test.csv')#, dtype={'drawing': np.array})\n# dft['drawing'] = dft['drawing'].map(vector_to_numpy)\n# dft = dft[dft['word'].isin(class_list[:10])].reset_index().drop('index', axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:23.995326Z","iopub.status.idle":"2023-09-13T19:27:23.995668Z","shell.execute_reply.started":"2023-09-13T19:27:23.995508Z","shell.execute_reply":"2023-09-13T19:27:23.995524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = MyDataset(dft['drawing'], train=False, ids=dft['key_id'])\ntest_loader = DataLoader(test_dataset, batch_size=128, drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:24.002357Z","iopub.status.idle":"2023-09-13T19:27:24.003122Z","shell.execute_reply.started":"2023-09-13T19:27:24.002875Z","shell.execute_reply":"2023-09-13T19:27:24.002899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(accuracy(vgg16_model, val_loader))","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:24.004382Z","iopub.status.idle":"2023-09-13T19:27:24.005114Z","shell.execute_reply.started":"2023-09-13T19:27:24.004882Z","shell.execute_reply":"2023-09-13T19:27:24.004904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# vgg16_model.predict(test_loader, i_0=406)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:24.006373Z","iopub.status.idle":"2023-09-13T19:27:24.007094Z","shell.execute_reply.started":"2023-09-13T19:27:24.006861Z","shell.execute_reply":"2023-09-13T19:27:24.006883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# basic_cnn_2 = BasicCNN()\n# basic_cnn_2.load_state_dict(torch.load('first_model.pt'))\n# # basic_cnn_2.predict(test_loader)\n# basic_cnn_3 = BasicCNN()\n# # train(basic_cnn_3, train_loader, cnn_optimizer, loss_fn, ps=2)\n\n# with torch.no_grad():\n#     print(basic_cnn_2.forward(next(iter(test_loader))[0]))\n# # basic_cnn.eval()\n# with torch.no_grad():\n#     count = 0\n#     correct = 0\n#     for data, targets in iter(dataloader):\n#         outputs = model.forward(data)\n#         predicted = outputs.max(1)[1] # Maximum output is predicted class\n#         count += len(targets) # Total length of datasetS\n#         correct += (predicted == targets).sum().item()\n#         # This gives a tensor of True and False values and adds no. of True values to correct each iteration\n#     print((predicted == targets).sum().item())\n#     accuracy = correct/count\n#     return accuracy\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:24.008383Z","iopub.status.idle":"2023-09-13T19:27:24.009117Z","shell.execute_reply.started":"2023-09-13T19:27:24.008886Z","shell.execute_reply":"2023-09-13T19:27:24.008909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(accuracy(basic_cnn, val_loader))\n# print(accuracy(inception_v3_model, val_loader))","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:24.010365Z","iopub.status.idle":"2023-09-13T19:27:24.011083Z","shell.execute_reply.started":"2023-09-13T19:27:24.010855Z","shell.execute_reply":"2023-09-13T19:27:24.010877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"basic_cnn_3.predict(test_loader)\n# inception_v3_model.predict(test_loader)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:27:24.012379Z","iopub.status.idle":"2023-09-13T19:27:24.013100Z","shell.execute_reply.started":"2023-09-13T19:27:24.012868Z","shell.execute_reply":"2023-09-13T19:27:24.012891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}