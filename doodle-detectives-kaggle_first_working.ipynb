{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np, pandas as pd, matplotlib.pyplot as plt\nimport torch, torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import StratifiedKFold, KFold\nimport torchvision.models, torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\ntorch.manual_seed(0)\nnp.random.seed(0)\n\ndevice = torch.device('cuda')","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import gc\n# gc.collect()\n# torch.cuda.empty_cache()","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image, ImageDraw\nimport numpy as np\nimport json\n\ndef vector_to_numpy(drawing, side=256):\n    image = vector_to_image(drawing, side)\n    image_array = np.array(image)\n    return image_array\n\ndef vector_to_image(drawing, side=256):\n    drawing = json.loads(drawing)\n    min_x, min_y, max_x, max_y = calculate_bounding_box(drawing)\n\n    # Calculate the offset to center the drawing within the canvas\n    offset_x = (side - (max_x - min_x + 1)) // 2\n    offset_y = (side - (max_y - min_y + 1)) // 2\n\n    image = Image.new('L', (side, side), color='white')  # Create a white canvas\n    draw = ImageDraw.Draw(image)\n\n    for x, y in drawing:\n        xy = [(x0 - min_x + offset_x, y0 - min_y + offset_y) for x0, y0 in zip(x, y)]\n        draw.line(xy, fill='black', width=1)\n\n    return image\n\ndef calculate_bounding_box(drawing):\n    all_x = [x for x, _ in drawing]\n    all_y = [y for _, y in drawing]\n\n    min_x = min(min(x) for x in all_x)\n    min_y = min(min(y) for y in all_y)\n    max_x = max(max(x) for x in all_x)\n    max_y = max(max(y) for y in all_y)\n\n    return min_x, min_y, max_x, max_y","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/doodle-detectives-aiclubiitm/train.csv') #, dtype={'drawing': np.array})\nclass_list = df['word'].unique()\nclasses = {word: index for index, word in enumerate(class_list)}\ndef prediction_to_words(prediction):\n    return ' '.join((class_list[p] for p in prediction))\n# df = df.sample(n=100_000).reset_index().drop('index', axis=1)\n# df = df[df['word'].isin(class_list[:10])].reset_index().drop('index', axis=1)\n# df['drawing'] = df['drawing'].map(vector_to_numpy)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(classes, class_list, sep='\\n')","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose(\n    [\n#      transforms.Resize((28, 28)),\n     transforms.Lambda(lambda x: x.repeat(1,3, 1, 1)),\n    #  transforms.Lambda(lambda x: print(x.shape)),\n    #  transforms.Grayscale(num_output_channels=3),\n    #  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n     ])\nvgg16 = torchvision.models.vgg16(weights=torchvision.models.VGG16_Weights.DEFAULT)\n","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BasicCNN(nn.Module):\n    def __init__(self):\n        nn.Module.__init__(self)\n        self.convolutions = nn.Sequential(\n            nn.MaxPool2d(8),\n            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n            # 1 input image. If we had an RGB image, it would be Conv2d(3, 32, 3, padding=1)\n            # 32 output images, i.e, 32 kernels and 32 output images are produced\n            nn.ReLU(),\n            # The activation function\n            nn.MaxPool2d(2),\n            # Pooling with 2 x 2 blocks\n            nn.Conv2d(32, 64, 3, padding=1),\n            # Now we have those 32 images and we make 64 from them\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n            # Pooling again\n        )\n        self.fully_connected = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear((28*28*64)//16, 512),\n            # The image shape was initially 28 x 28, by pooling we've made it 7 x 7, so we divide by 16\n            # We multiply by 64 because the model has learnt 64 features.\n            nn.Linear(512, 101),\n#             nn.Linear(128, 101)\n            # We have 10 output neurons (1 for each class)\n        )\n    def forward(self, inputs):\n        # inputs = inputs.reshape([inputs.shape[1], inputs.shape[0], 256, 256])\n        # print(type(inputs))\n#         inputs = transforms.Compose([transforms.Resize((28, 28))])(inputs)\n        x = self.convolutions(inputs.to(device))\n        # Functions in convolution layers are run\n        x = self.fully_connected(x)\n        # Functions in fully connected layer are run\n        return x\n    def predict(self, test_loader, out='SUBMISSION.csv', out_small='sub', i_0=0): # out = None may not be implemented\n        \"\"\"\n        Returns the predictions in a csv chosen by out, i_0 is in case you crash and have already done some stuff\n        \"\"\"\n        self.eval()\n        if not out: total_predictions=[]\n        for i, (data, ids) in enumerate(iter(test_loader)):\n            if i_0 > i: continue\n            predictions = torch.topk(self.forward(data), 3, dim=1)[1]\n            predictions = (prediction_to_words(p) for p in predictions)\n            if out:\n                df = pd.DataFrame({'key_id': ids, 'word': predictions})# dtype={'key_id': np.int64, 'word': np.array})\n                # df['predictions'] = df['predictions'].map(prediction_to_words)\n                df.to_csv(f'{out_small}_{i}.csv', index=False)\n            else: total_predictions.append(predictions)\n        if not out: return total_predictions\n        else:\n            total_predictions = []\n            for j in range(i+1):\n                total_predictions.append(pd.read_csv(f'{out_small}_{j}.csv'))\n            total_predictions = pd.concat(total_predictions)\n            total_predictions.to_csv(out, index=False)\n\n# le = preprocessing.LabelEncoder()\nclass MyDataset():\n    def __init__(self, data, targets=None, ids=None, train=True):\n        self.data = data\n        self.train = train\n        if train: \n            self.targets = targets.map(lambda target: classes[target])\n        if ids is not None: self.ids = ids\n    def __len__(self):\n        return len(self.data)\n    def __getitem__(self, i):\n        img = 1 - vector_to_numpy(self.data.loc[i], side=224)//250\n        if self.train: return (torch.tensor(img, dtype=torch.float32).reshape((1, *img.shape))), torch.tensor(self.targets[i], dtype=torch.int64)\n        if self.ids is not None: return (torch.tensor(img, dtype=torch.float32).reshape((1, *img.shape))), torch.tensor(self.ids[i], dtype=torch.int64)\n        return (torch.tensor(img, dtype=torch.float32).reshape((1, *img.shape)))","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 0\nvgg_length = len(list(vgg16.features.parameters()))\nfor param in vgg16.features.parameters():\n    if i < vgg_length - 4: param.requires_grad = False","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VGG16(nn.Module):\n    def __init__(self):\n        nn.Module.__init__(self)\n        self.convolutions = vgg16\n        self.extra = nn.Sequential(\n            nn.Linear(1000, 101), # This was my 1st guess at the no of outputs in VGG16, I was so surprised when it worked\n            nn.Softmax(dim=1)\n        )\n    def forward(self, inputs):\n        # inputs = inputs.reshape([inputs.shape[1], inputs.shape[0], 256, 256])\n        # print(type(inputs))\n        inputs = transform(inputs).to(device=device)\n        x = self.convolutions(inputs)\n        x = self.extra(x)\n        # Functions in fully connected layer are run\n        return x\n    def predict(self, test_loader, out='SUBMISSION.csv', out_small='sub', i_0=0): # out = None may not be implemented\n        \"\"\"\n        Returns the predictions in a csv chosen by out, i_0 is in case you crash and have already done some stuff\n        \"\"\"\n        self.eval()\n        if not out: total_predictions=[]\n        for i, (data, ids) in enumerate(iter(test_loader)):\n            if i_0 > i: continue\n            predictions = torch.topk(self.forward(data), 3, dim=1)[1]\n            predictions = (prediction_to_words(p) for p in predictions)\n            if out:\n                df = pd.DataFrame({'key_id': ids, 'word': predictions})# dtype={'key_id': np.int64, 'word': np.array})\n                # df['predictions'] = df['predictions'].map(prediction_to_words)\n                df.to_csv(f'{out_small}_{i}.csv', index=False)\n            else: total_predictions.append(predictions)\n        if not out: return total_predictions\n        else:\n            total_predictions = []\n            for j in range(i+1):\n                total_predictions.append(pd.read_csv(f'{out_small}_{j}.csv'))\n            total_predictions = pd.concat(total_predictions)\n            total_predictions.to_csv(out, index=False)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining one epoch of training\ndef train(model, train_loader, optimizer, loss, ps=50):\n    # We train the appropriate model with the input data and the appropriate optimizer\n    # ps is how often we print the accuracy\n    train_iter = iter(train_loader)\n    model.train()\n    # Puts model in train mode\n    for i, (data, targets) in enumerate(train_iter):\n        # i is iteration, data = 1 mini batch of images, targets = 1 mini batch target values\n        # This repeats for all mini batches \n        # print(targets)\n        targets = targets.to(device)\n        outputs = model.forward(data) # Forward pass\n        loss_val = loss(outputs, targets) # Loss computation\n        # print(targets)\n        optimizer.zero_grad()  # Ensures gradients stored in optimizer are reset before each backward pass\n        loss_val.backward() # Backward pass\n        optimizer.step() # Backward pass\n\n        if ps and i % ps == 0:\n            model.eval()\n            # Puts model in evaluation mode, so we \n            with torch.no_grad():\n                print(f\"Loss is {loss_val}\")\n                predicted = outputs.max(1)[1]\n                correct = (predicted == targets).sum().item()\n                accuracy = correct/len(targets)\n                print(f\"Train accuracy is {accuracy*100:.3f}%\")\ndef accuracy(model, test):\n    # Evaluate a model given a test loader\n    model.eval()\n    with torch.no_grad():\n        count = 0\n        correct = 0\n        for data, targets in iter(test):\n            targets = targets.to(device)\n            outputs = model.forward(data)\n#             predicted = outputs.max(1)[1] # Maximum output is predicted class\n            predictions = torch.topk(outputs, 3, dim=1)[1]\n            pred_1 = predictions[:, 0]\n            pred_2 = predictions[:, 1]\n            pred_3 = predictions[:, 2]\n            count += len(targets) # Total length of datasetS\n            correct += (pred_1 == targets).sum().item() + (pred_2 == targets).sum().item() + (pred_3 == targets).sum().item()\n            # This gives a tensor of True and False values and adds no. of True values to correct each iteration\n        # print((predicted == targets).sum().item())\n        accuracy = correct/count\n        return accuracy","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"basic_cnn = BasicCNN().to(device)\ncnn_optimizer = torch.optim.Adam(basic_cnn.parameters(), lr=2e-3)\nloss_fn = nn.CrossEntropyLoss().to(device)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for train_index, val_index in KFold(n_splits=5).split(df['drawing'], df['word']):\n    df_train = df.loc[train_index].reset_index().drop('index', axis=1)\n    df_val = df.loc[val_index].reset_index().drop('index', axis=1)\n    break\ntrain_dataset = MyDataset(df_train['drawing'], df_train['word'])","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(next(iter(train_loader)))","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_loader.targets.loc[0]\ndf_train","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train(basic_cnn, train_loader, cnn_optimizer, loss_fn)\ntorch.save(basic_cnn.state_dict(), 'first_model.pt')","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16_model = VGG16()\nvgg16_model.to(device)\nvgg16_optim = torch.optim.Adam(vgg16_model.parameters(), lr=2e-3)\nvgg_loss = nn.CrossEntropyLoss().to(device)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train(vgg16_model, train_loader, vgg16_optim, vgg_loss)\ntorch.save(basic_cnn.state_dict(), 'vgg16_model.pt')","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_set = MyDataset(df_val['drawing'], df_val['word'])\nval_loader = DataLoader(val_set, batch_size=128)\n# print(accuracy(basic_cnn, val_loader))/","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dft = pd.read_csv('/kaggle/input/doodle-detectives-aiclubiitm/test.csv')#, dtype={'drawing': np.array})\n# dft['drawing'] = dft['drawing'].map(vector_to_numpy)\n# dft = dft[dft['word'].isin(class_list[:10])].reset_index().drop('index', axis=1)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = MyDataset(dft['drawing'], train=False, ids=dft['key_id'])\ntest_loader = DataLoader(test_dataset, batch_size=128, drop_last=False)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(accuracy(vgg16_model, val_loader))","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# vgg16_model.predict(test_loader, i_0=406)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"basic_cnn_2 = BasicCNN()\nbasic_cnn_2.load_state_dict(torch.load('first_model.pt'))\n# basic_cnn_2.predict(test_loader)\nbasic_cnn_3 = BasicCNN()\n# train(basic_cnn_3, train_loader, cnn_optimizer, loss_fn, ps=2)\n\n# with torch.no_grad():\n#     print(basic_cnn_2.forward(next(iter(test_loader))[0]))\n# # basic_cnn.eval()\n# with torch.no_grad():\n#     count = 0\n#     correct = 0\n#     for data, targets in iter(dataloader):\n#         outputs = model.forward(data)\n#         predicted = outputs.max(1)[1] # Maximum output is predicted class\n#         count += len(targets) # Total length of datasetS\n#         correct += (predicted == targets).sum().item()\n#         # This gives a tensor of True and False values and adds no. of True values to correct each iteration\n#     print((predicted == targets).sum().item())\n#     accuracy = correct/count\n#     return accuracy\n","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# basic_cnn_3.predict(test_loader)\nprint(accuracy(basic_cnn, val_loader))","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"basic_cnn.predict(test_loader)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]}]}